{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the single marital status dataset\n",
    "df = pd.read_csv(\"train_divorced_reduced.csv\")\n",
    "\n",
    "# Define feature types\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_features = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n",
    "binary_features = ['default', 'housing', 'loan', 'y']\n",
    "\n",
    "# pre-processing categorical_features\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_features:\n",
    "    if column in df.columns: \n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "for column in binary_features:\n",
    "    if column in df.columns:\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Function Definitions\n",
    "def preprocess_data(df):\n",
    "    X = df.drop(columns=['y'])\n",
    "    y = df['y']\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "def evaluate_model(model, X_valid, y_valid):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, zero_division=1))\n",
    "    \n",
    "# Define and fit ANN model\n",
    "def fit_ann(X_train, y_train, X_valid, y_valid):\n",
    "    parameters = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "    model = MLPClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print the results of each hyperparameter combination\n",
    "    cv_results = grid_search.cv_results_\n",
    "    for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "        print(f\"Mean Test Score: {mean_score}, Parameters: {params}\")\n",
    "    \n",
    "    # Plot the mean test score for each hyperparameter combination\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    scores = cv_results['mean_test_score']\n",
    "    alphas = [param['alpha'] for param in cv_results['params']]\n",
    "    plt.plot(alphas, scores, marker='o')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel('Mean Test Score')\n",
    "    plt.title('Mean Test Score vs Alpha (ANN)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 5-fold cross-validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    fold_numbers = np.arange(1, 6)\n",
    "    mean_test_scores = grid_search.cv_results_['mean_test_score'][:5]  # Extract first 5 scores\n",
    "    fold_numbers = np.arange(1, len(mean_test_scores) + 1)\n",
    "    plt.plot(fold_numbers, mean_test_scores, marker='o')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('5-Fold Cross-Validation Accuracy (ANN)')\n",
    "    plt.xticks(fold_numbers)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the mean accuracy over 5 folds\n",
    "    print(\"Mean accuracy over 5 folds:\", grid_search.best_score_)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, zero_division=1))\n",
    "    \n",
    "    return best_model, grid_search.best_score_\n",
    "\n",
    "\n",
    "# Define and fit Decision Tree model\n",
    "def fit_decision_tree(X_train, y_train, X_valid, y_valid):\n",
    "    parameters = {'max_depth': [None, 5, 10, 15, 20]}\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print the results of each hyperparameter combination\n",
    "    cv_results = grid_search.cv_results_\n",
    "    for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "        print(f\"Mean Test Score: {mean_score}, Parameters: {params}\")\n",
    "    \n",
    "    # Plot the mean test score for each hyperparameter combination\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(parameters['max_depth'], grid_search.cv_results_['mean_test_score'], marker='o')\n",
    "    plt.xlabel('Max Depth')\n",
    "    plt.ylabel('Mean Test Score')\n",
    "    plt.title('Mean Test Score for Each Max Depth (Decision Tree)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 5-fold cross-validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    fold_numbers = np.arange(1, 6)\n",
    "    mean_test_scores = grid_search.cv_results_['mean_test_score'][:5]  # Extract first 5 scores\n",
    "    fold_numbers = np.arange(1, len(mean_test_scores) + 1)\n",
    "    plt.plot(fold_numbers, mean_test_scores, marker='o')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('5-Fold Cross-Validation Accuracy (Decision Tree)')\n",
    "    plt.xticks(fold_numbers)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the mean accuracy over 5 folds\n",
    "    print(\"Mean accuracy over 5 folds:\", grid_search.best_score_)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, zero_division=1))\n",
    "    \n",
    "    return best_model, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_train, X_valid, y_train, y_valid = preprocess_data(df)\n",
    "# Perform grid search, print the results, and plot the graphs\n",
    "best_model_ann, best_score_ann = fit_ann(X_train, y_train, X_valid, y_valid)\n",
    "print(\"Best Score:\", best_model_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_train, X_valid, y_train, y_valid = preprocess_data(df)\n",
    "\n",
    "# Perform grid search, print the results, and plot the graphs\n",
    "best_model_dt, best_score_dt = fit_decision_tree(X_train, y_train, X_valid, y_valid)\n",
    "print(\"Best Score:\", best_score_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "# Best hyperparameter values\n",
    "X_train, X_valid, y_train, y_valid = preprocess_data(df)\n",
    "model = MLPClassifier(alpha=0.01,random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Model performance: {accuracy}\")\n",
    "print(f\"Training runtime: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "# Best hyperparameter values\n",
    "X_train, X_valid, y_train, y_valid = preprocess_data(df)\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Model performance: {accuracy}\")\n",
    "print(f\"Training runtime: {training_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Predict the validation data\n",
    "# Load the single marital status dataset\n",
    "df_v = pd.read_csv(\"valid_divorced_reduced.csv\")\n",
    "\n",
    "## ANN\n",
    "X_train, X_valid, y_train, y_valid = preprocess_data(df_v)\n",
    "model = MLPClassifier(alpha=0.01)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "end_time = time.time()\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "runtime = end_time - start_time\n",
    "print(f\"Prediction performance (accuracy): {accuracy}\")\n",
    "print(f\"Runtime for testing: {runtime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "X_train, X_valid, y_train, y_valid = preprocess_data(df_v)\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "end_time = time.time()\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "runtime = end_time - start_time\n",
    "print(f\"Prediction performance (accuracy): {accuracy}\")\n",
    "print(f\"Runtime for testing: {runtime} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
